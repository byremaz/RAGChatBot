%%writefile app.py
import os
import pdfplumber
import fitz  # PyMuPDF
import time
import streamlit as st
from dotenv import load_dotenv
from langchain.embeddings import HuggingFaceEmbeddings
from langchain_groq import ChatGroq
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain_core.prompts import ChatPromptTemplate
from langchain.chains import create_retrieval_chain
from langchain_community.vectorstores import FAISS
from langchain.schema import Document

# Load environment variables from .env file
load_dotenv()

# Set the Groq API key
os.environ['GROQ_API_KEY'] = "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"

# Initialize the ChatGroq model
groq_api_key = os.getenv('GROQ_API_KEY')
llm = ChatGroq(model="llama3-70b-8192", api_key=groq_api_key)

# Define the prompt template
prompt = ChatPromptTemplate.from_template("""Answer the questions based on the provided context only.
Answer in Arabic only if the input in arabic.
Provide the most accurate response based on the question.
<context>
{context}
<context>
Questions: {input}
""")

# Function to extract text and tables from a PDF using PyMuPDF and pdfplumber
def load_pdf_with_pymupdf(pdf_file_path):
    doc = fitz.open(pdf_file_path)
    extracted_text = []

    for page_num in range(len(doc)):
        page = doc[page_num]
        text = page.get_text()  # Extracts text directly from the page
        extracted_text.append(text)

    # Use pdfplumber to extract tables specifically
    with pdfplumber.open(pdf_file_path) as pdf:
        for page_num, page in enumerate(pdf.pages):
            tables = page.extract_tables()  # Extract tables
            for table in tables:
                table_text = '\n'.join(['\t'.join([str(cell) if cell is not None else '' for cell in row]) for row in table])
                extracted_text.append(table_text)

    return extracted_text

# Function to load and combine text from multiple PDFs
def load_multiple_pdfs(pdf_file_paths):
    all_text = []
    for pdf_file_path in pdf_file_paths:
        all_text.extend(load_pdf_with_pymupdf(pdf_file_path))
    return all_text

# Vectorize extracted text and prepare for retrieval
def vector_embedding(pdf_file_paths):
    embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2", model_kwargs={'device': 'cpu'})
    doc_text = load_multiple_pdfs(pdf_file_paths)  # Load and combine text from all PDFs

    # Convert extracted text into Document format
    final_documents = [Document(page_content=text) for text in doc_text]
    vectors = FAISS.from_documents(final_documents, embeddings)  # Vectorize with embeddings
    return vectors, final_documents

# Function to process and answer a user question from multiple PDFs
def process_question(pdf_file_paths, question):
    # Process the documents for embeddings
    vectors, final_documents = vector_embedding(pdf_file_paths)  # Generate embeddings

    # Create the document chain for querying
    document_chain = create_stuff_documents_chain(llm, prompt)
    retriever = vectors.as_retriever()
    retrieval_chain = create_retrieval_chain(retriever, document_chain)

    # Measure the response time
    start = time.process_time()
    response = retrieval_chain.invoke({'input': question})
    response_time = time.process_time() - start

    # Return the results
    return response_time, response['answer']

# Streamlit UI elements
st.set_page_config(page_title="GenAi Bot", layout="wide")

# Customize the style to decrease font size
st.markdown("""
    <style>
    body {
        font-size: 14px;
    }
    .stTextInput input {
        font-size: 16px;
    }
    .stTextArea textarea {
        font-size: 16px;
    }
    .stButton button {
        font-size: 16px;
    }
    .stMarkdown {
        font-size: 14px;
    }
    </style>
""", unsafe_allow_html=True)

# Title and description
st.title("GenAi Bot")
st.write("Answer questions based on the provided PDFs.")

# Predefined paths to your PDFs
uploaded_pdf_paths = [
    "/content/480_0_2022-02-28_14-06-24_En.pdf",
    "/content/480_0_2023-02-28_15-08-10_En.pdf",
    "/content/480_0_2024-02-28_10-51-24_En.pdf"
]

# Input field for the question
question = st.text_input("Enter your question:")

if question:
    # Process the question and display the answer
    response_time, answer = process_question(uploaded_pdf_paths, question)

    # Display response time and answer
    st.subheader(f"Response Time: {response_time:.2f} seconds")
    st.subheader(f"Answer: {answer}")



